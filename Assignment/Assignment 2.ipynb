{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, \n",
    "              'sqft_living15':float, 'grade':int, 'yr_renovated':int,\n",
    "              'price':float, 'bedrooms':float, 'zipcode':str, 'long':float,\n",
    "              'sqft_lot15':float, 'sqft_living':float, 'floors':str, \n",
    "              'condition':int, 'lat':float, 'date':str, \n",
    "              'sqft_basement':int, 'yr_built':int, 'id':str,\n",
    "              'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data frame from numpy data\n",
    "def get_numpy_data(data, features, output):\n",
    "    features = ['Constant'] + features\n",
    "    \n",
    "    data['Constant'] = 1\n",
    "    print(data[features].head())\n",
    "    \n",
    "    feature_matrix, output = list(map(np.array, [data[features], output]))                              \n",
    "    \n",
    "    return (feature_matrix, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The function 'predict_output' takes 'feature_matrix' and 'weights' \n",
    "as input and returns the predicted values.\n",
    "'''\n",
    "def predict_output(feature_matrix, weights):\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    \n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/shrikrishna/Desktop/Coursera Machine Learning/Regression/Week 5/Assignment 2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path\n",
    "path = '/home/shrikrishna/Desktop/Coursera Machine Learning/Regression/Week 5/Assignment/'\n",
    "\n",
    "#Read the files\n",
    "sales = pd.read_csv(path + 'kc_house_data.csv')\n",
    "training = pd.read_csv(path + 'wk3_kc_house_train_data.csv')\n",
    "testing = pd.read_csv(path + 'wk3_kc_house_test_data.csv')\n",
    "validation = pd.read_csv(path + 'wk3_kc_house_valid_data.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the house dataset, features vary wildly in their relative magnitude: ‘sqft_living’ is very large overall compared to ‘bedrooms’, for instance. As a result, weight for ‘sqft_living’ would be much smaller than weight for ‘bedrooms’. This is problematic because “small” weights are dropped first as l1_penalty goes up.\n",
    "\n",
    "To give equal considerations for all features, we need to normalize features as discussed in the lectures: we divide each feature by its 2-norm so that the transformed feature has norm 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize the features\n",
    "def normalize_features(feature_matrix):\n",
    "    \n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)\n",
    "    \n",
    "    normalized_features = feature_matrix/norms\n",
    "    \n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of Coordinate Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|).\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We seek to obtain a sparse set of weights by minimizing the LASSO cost function\n",
    "'''\n",
    "SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|).\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Pick a coordinate i\n",
    "2. Compute w[i] that minimizes the LASSO cost function\n",
    "3. Repeat the two steps for all coordinates, multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor this assignment, we use cyclical coordinate descent with normalized \\nfeatures, where we cycle through coordinates 0 to (d-1) in order, \\nand assume the features were normalized as discussed above. \\nThe formula for optimizing each coordinate is as follows:\\n\\n       ┌ (ro[i] + lambda/2)    if ro[i] < -lambda/2\\nw[i] = ├ 0                     if -lambda/2 <= ro[i] <= lambda/2\\n       └ (ro[i] - lambda/2)    if ro[i] > lambda/2\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For this assignment, we use cyclical coordinate descent with normalized \n",
    "features, where we cycle through coordinates 0 to (d-1) in order, \n",
    "and assume the features were normalized as discussed above. \n",
    "The formula for optimizing each coordinate is as follows:\n",
    "\n",
    "       ┌ (ro[i] + lambda/2)    if ro[i] < -lambda/2\n",
    "w[i] = ├ 0                     if -lambda/2 <= ro[i] <= lambda/2\n",
    "       └ (ro[i] - lambda/2)    if ro[i] > lambda/2\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ro[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w[0] = ro[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Consider a simple model with 2 features: ‘sqft_living’ and ‘bedrooms’. The output is ‘price’.\n",
    "\n",
    "First, run get_numpy_data() (or equivalent) to obtain a feature matrix with 3 columns (constant column added). Use the entire ‘sales’ dataset for now.\n",
    "Normalize columns of the feature matrix. Save the norms of original features as ‘norms’.\n",
    "Set initial weights to [1,4,1].\n",
    "Make predictions with feature matrix and initial weights.\n",
    "Compute values of ro[i], where\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a simple model with 2 features: ‘sqft_living’ and ‘bedrooms’. The output is ‘price’.\n",
    "\n",
    "First, run get_numpy_data() (or equivalent) to obtain a feature matrix with 3 columns (constant column added). Use the entire ‘sales’ dataset for now.\n",
    "\n",
    "Normalize columns of the feature matrix. Save the norms of original\n",
    "features as ‘norms’.\n",
    "\n",
    "Set initial weights to [1,4,1].\n",
    "\n",
    "Make predictions with feature matrix and initial weights.\n",
    "\n",
    "Compute values of ro[i], where \n",
    "ro[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Constant  sqft_living  bedrooms\n",
      "0         1         1180         3\n",
      "1         1         2570         3\n",
      "2         1          770         2\n",
      "3         1         1960         4\n",
      "4         1         1680         3\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Consider a simple model with 2 features:\n",
    "‘sqft_living’ and ‘bedrooms’. The output is ‘price’.\n",
    "'''\n",
    "features = ['sqft_living','bedrooms']\n",
    "output = 'price'\n",
    "\n",
    "#Use the entire ‘sales’ dataset for now.\n",
    "feature_matrix, output = get_numpy_data(sales, features, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set initial weights\n",
    "initial_weights = np.array([1,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions with feature matrix and initial weights\n",
    "predictions = predict_output(feature_matrix, initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute values of ro[i], where\n",
    "#ro[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Quiz Question: Recall that, whenever ro[i] falls between -l1_penalty/2 and l1_penalty/2, the corresponding weight w[i] is sent to zero. Now suppose we were to take one step of coordinate descent on either feature 1 or feature 2. What range of values of l1_penalty would not set w[1] zero, but would set w[2] to zero, if we were to take a step in that coordinate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Quiz Question: What range of values of l1_penalty would set both w[1] and w[2] to zero, if we were to take a step in that coordinate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
